{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.2. Importing Datasets through Kaggle API.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2gCkqe4ctyQFg1TR+SXtP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carissafarry/study-ml2/blob/main/4.2.%20Importing%20Datasets%20through%20Kaggle%20API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krqHRAMN8SKJ"
      },
      "source": [
        "API - Application Programming Interface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwqYl9kPCatF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd8d520-dc76-4049-fb3d-730eac56c7af"
      },
      "source": [
        "# installing the Kaggle library\n",
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feg7yUtK9LJ6"
      },
      "source": [
        "Upload your Kaggle json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ftSCebk9J2H"
      },
      "source": [
        "# configuring the path of Kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2NQ45u8-c8W"
      },
      "source": [
        "Importing the Earthquake Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcEZhZOQ-bdI",
        "outputId": "61251e24-c2b2-4a84-f476-7f7fc60e58a4"
      },
      "source": [
        "# API to fetch the dataset from Kaggle\n",
        "!kaggle competitions download -c LANL-Earthquake-Prediction"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading seg_0042cc.csv to /content\n",
            "  0% 0.00/319k [00:00<?, ?B/s]\n",
            "100% 319k/319k [00:00<00:00, 47.3MB/s]\n",
            "Downloading seg_0125d9.csv to /content\n",
            "  0% 0.00/320k [00:00<?, ?B/s]\n",
            "100% 320k/320k [00:00<00:00, 102MB/s]\n",
            "Downloading seg_010eab.csv to /content\n",
            "  0% 0.00/316k [00:00<?, ?B/s]\n",
            "100% 316k/316k [00:00<00:00, 100MB/s]\n",
            "Downloading seg_007a37.csv to /content\n",
            "  0% 0.00/325k [00:00<?, ?B/s]\n",
            "100% 325k/325k [00:00<00:00, 101MB/s]\n",
            "Downloading seg_004314.csv to /content\n",
            "  0% 0.00/360k [00:00<?, ?B/s]\n",
            "100% 360k/360k [00:00<00:00, 115MB/s]\n",
            "Downloading seg_0012b5.csv to /content\n",
            "  0% 0.00/321k [00:00<?, ?B/s]\n",
            "100% 321k/321k [00:00<00:00, 169MB/s]\n",
            "Downloading seg_00cc91.csv to /content\n",
            "  0% 0.00/329k [00:00<?, ?B/s]\n",
            "100% 329k/329k [00:00<00:00, 108MB/s]\n",
            "Downloading seg_00648a.csv to /content\n",
            "  0% 0.00/329k [00:00<?, ?B/s]\n",
            "100% 329k/329k [00:00<00:00, 166MB/s]\n",
            "Downloading seg_00030f.csv to /content\n",
            "  0% 0.00/321k [00:00<?, ?B/s]\n",
            "100% 321k/321k [00:00<00:00, 103MB/s]\n",
            "Downloading seg_00184e.csv to /content\n",
            "  0% 0.00/320k [00:00<?, ?B/s]\n",
            "100% 320k/320k [00:00<00:00, 102MB/s]\n",
            "Downloading seg_00be11.csv to /content\n",
            "  0% 0.00/330k [00:00<?, ?B/s]\n",
            "100% 330k/330k [00:00<00:00, 97.4MB/s]\n",
            "Downloading seg_00e5f7.csv to /content\n",
            "  0% 0.00/319k [00:00<?, ?B/s]\n",
            "100% 319k/319k [00:00<00:00, 98.6MB/s]\n",
            "Downloading seg_003339.csv to /content\n",
            "  0% 0.00/310k [00:00<?, ?B/s]\n",
            "100% 310k/310k [00:00<00:00, 98.5MB/s]\n",
            "Downloading seg_00a37e.csv to /content\n",
            "  0% 0.00/332k [00:00<?, ?B/s]\n",
            "100% 332k/332k [00:00<00:00, 101MB/s]\n",
            "Downloading seg_004cd2.csv to /content\n",
            "  0% 0.00/315k [00:00<?, ?B/s]\n",
            "100% 315k/315k [00:00<00:00, 97.7MB/s]\n",
            "Downloading seg_004f1f.csv to /content\n",
            "  0% 0.00/324k [00:00<?, ?B/s]\n",
            "100% 324k/324k [00:00<00:00, 105MB/s]\n",
            "Downloading seg_00c35b.csv to /content\n",
            "  0% 0.00/312k [00:00<?, ?B/s]\n",
            "100% 312k/312k [00:00<00:00, 96.2MB/s]\n",
            "Downloading seg_00f3b9.csv to /content\n",
            "  0% 0.00/336k [00:00<?, ?B/s]\n",
            "100% 336k/336k [00:00<00:00, 101MB/s]\n",
            "Downloading seg_004ee5.csv to /content\n",
            "  0% 0.00/324k [00:00<?, ?B/s]\n",
            "100% 324k/324k [00:00<00:00, 93.9MB/s]\n",
            "Downloading seg_006e4a.csv to /content\n",
            "  0% 0.00/325k [00:00<?, ?B/s]\n",
            "100% 325k/325k [00:00<00:00, 207MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "100% 2.03G/2.03G [00:22<00:00, 106MB/s]\n",
            "100% 2.03G/2.03G [00:22<00:00, 96.7MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/33.3k [00:00<?, ?B/s]\n",
            "100% 33.3k/33.3k [00:00<00:00, 28.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhyZ7WYE-rhy",
        "outputId": "1ad1e9aa-bf26-4c8d-c731-abf898331719"
      },
      "source": [
        "# extracting the compressed Dataset\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/train.csv.zip'\n",
        "\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVRf4MTUAaFl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}